{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manguetownson/Classificacao_de_dispositivos_python_cnn/blob/main/dispositives_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpR0mVmKqfAC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import imageio\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeYcQ-LiPP4X",
        "outputId": "de8edbd6-b845-43cb-a024-952dbea87fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp3d9MPgJW22",
        "outputId": "4ace1291-bb60-4f02-c770-b6894f7e690a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=1voZSk_amRVxnJ30FEL2GiSooF_cnGZtw\n",
            "From (redirected): https://drive.google.com/uc?id=1voZSk_amRVxnJ30FEL2GiSooF_cnGZtw&confirm=t&uuid=1070807e-17ef-4542-9613-a9328b03b4bb\n",
            "To: /content/dataset_dispositivos.zip\n",
            "100% 1.28G/1.28G [00:25<00:00, 49.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1voZSk_amRVxnJ30FEL2GiSooF_cnGZtw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh6mAwJZQLIf"
      },
      "outputs": [],
      "source": [
        "!unzip -q 'dataset_dispositivos.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSqrcode6_kH",
        "outputId": "6d6938cc-07ce-423d-f1a5-9545207b56a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2182 images belonging to 5 classes.\n",
            "Found 544 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2,\n",
        "    dtype='float32'\n",
        ")\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    '/content/dataset_dispositivos/',  #em caso de teste, alterar o nome do arquivo em /content de \"dataset dispositivos\" para dataset_dispositivos\"\n",
        "    target_size=(224, 224),            #também alterar a classe \"dispositivos_móveis\" para \"dispositivos_moveis (para que não haja erros, pois cometi esse deslize na criação da base)\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    '/content/dataset_dispositivos/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfHa6r0mEj2p"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (4, 4), input_shape=(224, 224, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (4, 4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (4, 4)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))  # Ajuste para corresponder ao número real de classes (5)\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evlyLEO2Em8k",
        "outputId": "19e7f69e-cd0e-4bf6-fd52-9555654c2ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "69/69 [==============================] - 416s 6s/step - loss: 1.5253 - accuracy: 0.3034 - val_loss: 1.3964 - val_accuracy: 0.4189\n",
            "Epoch 2/50\n",
            "69/69 [==============================] - 395s 6s/step - loss: 1.3269 - accuracy: 0.3918 - val_loss: 1.2178 - val_accuracy: 0.4028\n",
            "Epoch 3/50\n",
            "69/69 [==============================] - 400s 6s/step - loss: 1.2585 - accuracy: 0.4372 - val_loss: 1.0843 - val_accuracy: 0.5229\n",
            "Epoch 4/50\n",
            "69/69 [==============================] - 400s 6s/step - loss: 1.1523 - accuracy: 0.4945 - val_loss: 1.0995 - val_accuracy: 0.5101\n",
            "Epoch 5/50\n",
            "69/69 [==============================] - 403s 6s/step - loss: 1.1005 - accuracy: 0.5211 - val_loss: 0.9014 - val_accuracy: 0.6434\n",
            "Epoch 6/50\n",
            "69/69 [==============================] - 406s 6s/step - loss: 1.0468 - accuracy: 0.5761 - val_loss: 0.8566 - val_accuracy: 0.6810\n",
            "Epoch 7/50\n",
            "69/69 [==============================] - 395s 6s/step - loss: 0.9599 - accuracy: 0.6159 - val_loss: 0.8818 - val_accuracy: 0.7163\n",
            "Epoch 8/50\n",
            "69/69 [==============================] - 395s 6s/step - loss: 0.8883 - accuracy: 0.6416 - val_loss: 0.7995 - val_accuracy: 0.6622\n",
            "Epoch 9/50\n",
            "69/69 [==============================] - 409s 6s/step - loss: 0.8743 - accuracy: 0.6645 - val_loss: 0.7672 - val_accuracy: 0.7489\n",
            "Epoch 10/50\n",
            "69/69 [==============================] - 403s 6s/step - loss: 0.8048 - accuracy: 0.6943 - val_loss: 1.5406 - val_accuracy: 0.5133\n",
            "Epoch 11/50\n",
            "69/69 [==============================] - 396s 6s/step - loss: 0.7837 - accuracy: 0.7016 - val_loss: 0.6018 - val_accuracy: 0.7828\n",
            "Epoch 12/50\n",
            "69/69 [==============================] - 404s 6s/step - loss: 0.7059 - accuracy: 0.7287 - val_loss: 0.4939 - val_accuracy: 0.8313\n",
            "Epoch 13/50\n",
            "69/69 [==============================] - 399s 6s/step - loss: 0.7204 - accuracy: 0.7383 - val_loss: 0.4908 - val_accuracy: 0.8231\n",
            "Epoch 14/50\n",
            "69/69 [==============================] - 395s 6s/step - loss: 0.6864 - accuracy: 0.7516 - val_loss: 0.5122 - val_accuracy: 0.8341\n",
            "Epoch 15/50\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.7791"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=train_generator\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GnjR0LfcG4Oa",
        "outputId": "f6cb9b34-4386-45f0-d24f-cb7c6dc061c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 221 images belonging to 3 classes.\n",
            "Acurácia do modelo nos dados de teste: 0.8823529411764706\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "\n",
        "# Definir o caminho das pastas de treinamento e teste\n",
        "caminho_treinamento = '/content/dataset_dispositivos'\n",
        "\n",
        "\n",
        "# Definir dimensões das imagens\n",
        "largura, altura = 224, 224\n",
        "\n",
        "# Criar um objeto ImageDataGenerator para pré-processamento dos dados de teste\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Carregar os dados de teste\n",
        "dados_teste = test_datagen.flow_from_directory(\n",
        "    caminho_treinamento,\n",
        "    target_size=(largura, altura),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "previsoes = model.predict_generator(dados_teste, steps=dados_teste.samples)\n",
        "\n",
        "# Obter as classes preditas\n",
        "classes_preditas = np.argmax(previsoes, axis=1)\n",
        "\n",
        "# Obter as classes verdadeiras\n",
        "classes_verdadeiras = dados_teste.classes\n",
        "\n",
        "# Calcular a acurácia\n",
        "acuracia = np.mean(classes_preditas == classes_verdadeiras)\n",
        "print(\"Acurácia do modelo nos dados de teste:\", acuracia)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wSIl4VUSqJvL",
        "outputId": "d284d0c5-b011-4b43-b27b-bb89ef17e7f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 24s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications import VGG16\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create an instance of the VGG16 model with pre-trained weights\n",
        "vgg = VGG16(include_top=True,\n",
        "            weights=\"imagenet\",\n",
        "            classifier_activation=\"softmax\",\n",
        "            #input_tensor=(None),\n",
        "            #input_shape=(224, 224, 3),\n",
        "            #pooling=(2, 2),\n",
        "            #classes=1000,\n",
        "           )\n",
        "\n",
        "# Freeze the convolutional layers in the base model so they are not updated during training\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add your own classification layers on top of the base model\n",
        "model = Sequential()\n",
        "model.add(vgg)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJpoIlsgOnUf"
      },
      "outputs": [],
      "source": [
        "# Compile the model with a lower learning rate and categorical hinge loss\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model using the augmented data generator\n",
        "history_vgg16 = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    validation_data = train_generator,\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOV_lZJ-m4i6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohV9USMiQWLK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import load_model\n",
        "\n",
        "# Definir o caminho das pastas de treinamento e teste\n",
        "caminho_treinamento = '/content/treinamento'\n",
        "\n",
        "\n",
        "# Definir dimensões das imagens\n",
        "largura, altura = 224, 224\n",
        "\n",
        "# Criar um objeto ImageDataGenerator para pré-processamento dos dados de teste\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Carregar os dados de teste\n",
        "dados_teste = test_datagen.flow_from_directory(\n",
        "    caminho_teste,\n",
        "    target_size=(largura, altura),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Fazer previsões nos dados de teste\n",
        "previsoes = model.predict_generator(dados_teste, steps=dados_teste.samples)\n",
        "\n",
        "# Obter as classes preditas\n",
        "classes_preditas = np.argmax(previsoes, axis=1)\n",
        "\n",
        "# Obter as classes verdadeiras\n",
        "classes_verdadeiras = dados_teste.classes\n",
        "\n",
        "# Calcular a acurácia\n",
        "acuracia = np.mean(classes_preditas == classes_verdadeiras)\n",
        "print(\"Acurácia do modelo nos dados de teste:\", acuracia)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nol7hYwmfsUs"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.applications import VGG19\n",
        "\n",
        "# Create an instance of the VGG16 model with pre-trained weights\n",
        "vgg1 = VGG19(include_top=True,\n",
        "            weights=\"imagenet\",\n",
        "            classifier_activation=\"softmax\",\n",
        "            #input_tensor=(None),\n",
        "            #input_shape=(224, 224, 3),\n",
        "            #pooling=(2, 2),\n",
        "            #classes=1000,\n",
        "           )\n",
        "\n",
        "# Freeze the convolutional layers in the base model so they are not updated during training\n",
        "for layer in vgg1.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add your own classification layers on top of the base model\n",
        "model = Sequential()\n",
        "model.add(vgg1)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibs4xxpJiVS8"
      },
      "outputs": [],
      "source": [
        "# Compile the model with a lower learning rate and categorical hinge loss\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model using the augmented data generator\n",
        "history_vgg19 = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    validation_data = train_generator,\n",
        "                    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}